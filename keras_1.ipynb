{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markpotanin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_EPOCH = 200\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # количество предсказываемых классов\n",
    "OPTIMIZER = SGD() # используем SGD в качестве оптимизатора при бэкпропе\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRB2IAnCDiTx/65XcTNOWsh5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train состоит из 60000 строк, в каждой матрица размером 28x28  --> развернем их в 60000 x 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESHAPED = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рзавернем таргеты в бинарные таблички"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот собственно и модель из 3 строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax сплющивает k-мерный вектор, содержащий произвольные вещественные числа, в k-мерный вектор вещественных чисел из интервала (0,1). В нашем случае она аггрегирует 10 ответов, выданных предыдущим слоем из  10 нейронов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определенную модель теперь нужно откомпилировать, то есть привести к виду, допускающему исполнение базовой библиотекой (Theano или Tensorflow). Перед компиляцией необходимо выбрать:\n",
    "* Выбрать оптимизатор, то есть конкретный алгоритм, который будет обновлять веса в процессе обучения модели\n",
    "* Выбрать целевую функцию, которую оптимизатор использует для навигации по пространству весов\n",
    "* Оценить качество обученной модели\n",
    "\n",
    "categorical_crossentropy - как бинарная, только для нескольких классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 1.3536 - acc: 0.6821 - val_loss: 0.6753 - val_acc: 0.8496\n",
      "Epoch 2/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.5587 - acc: 0.8586 - val_loss: 0.4328 - val_acc: 0.8883\n",
      "Epoch 3/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.4245 - acc: 0.8851 - val_loss: 0.3637 - val_acc: 0.9013\n",
      "Epoch 4/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3721 - acc: 0.8955 - val_loss: 0.3289 - val_acc: 0.9072\n",
      "Epoch 5/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.9038 - val_loss: 0.3079 - val_acc: 0.9123\n",
      "Epoch 6/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.3200 - acc: 0.9090 - val_loss: 0.2912 - val_acc: 0.9183\n",
      "Epoch 7/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.3034 - acc: 0.9133 - val_loss: 0.2776 - val_acc: 0.9222\n",
      "Epoch 8/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.2896 - acc: 0.9175 - val_loss: 0.2681 - val_acc: 0.9251\n",
      "Epoch 9/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2779 - acc: 0.9208 - val_loss: 0.2587 - val_acc: 0.9281\n",
      "Epoch 10/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2673 - acc: 0.9237 - val_loss: 0.2495 - val_acc: 0.9305\n",
      "Epoch 11/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2577 - acc: 0.9265 - val_loss: 0.2447 - val_acc: 0.9302\n",
      "Epoch 12/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2491 - acc: 0.9291 - val_loss: 0.2353 - val_acc: 0.9331\n",
      "Epoch 13/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2412 - acc: 0.9312 - val_loss: 0.2297 - val_acc: 0.9343\n",
      "Epoch 14/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2339 - acc: 0.9333 - val_loss: 0.2232 - val_acc: 0.9363\n",
      "Epoch 15/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2268 - acc: 0.9353 - val_loss: 0.2185 - val_acc: 0.9383\n",
      "Epoch 16/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2201 - acc: 0.9371 - val_loss: 0.2125 - val_acc: 0.9393\n",
      "Epoch 17/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2137 - acc: 0.9390 - val_loss: 0.2090 - val_acc: 0.9414\n",
      "Epoch 18/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2078 - acc: 0.9408 - val_loss: 0.2035 - val_acc: 0.9430\n",
      "Epoch 19/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.2021 - acc: 0.9421 - val_loss: 0.1982 - val_acc: 0.9447\n",
      "Epoch 20/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1966 - acc: 0.9446 - val_loss: 0.1952 - val_acc: 0.9445\n",
      "Epoch 21/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1916 - acc: 0.9453 - val_loss: 0.1904 - val_acc: 0.9463\n",
      "Epoch 22/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1869 - acc: 0.9464 - val_loss: 0.1861 - val_acc: 0.9483\n",
      "Epoch 23/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1819 - acc: 0.9479 - val_loss: 0.1821 - val_acc: 0.9479\n",
      "Epoch 24/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1775 - acc: 0.9489 - val_loss: 0.1793 - val_acc: 0.9495\n",
      "Epoch 25/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1731 - acc: 0.9506 - val_loss: 0.1760 - val_acc: 0.9507\n",
      "Epoch 26/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1690 - acc: 0.9517 - val_loss: 0.1727 - val_acc: 0.9525\n",
      "Epoch 27/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1650 - acc: 0.9529 - val_loss: 0.1700 - val_acc: 0.9528\n",
      "Epoch 28/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1612 - acc: 0.9534 - val_loss: 0.1666 - val_acc: 0.9537\n",
      "Epoch 29/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1574 - acc: 0.9549 - val_loss: 0.1641 - val_acc: 0.9550\n",
      "Epoch 30/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1540 - acc: 0.9554 - val_loss: 0.1608 - val_acc: 0.9557\n",
      "Epoch 31/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1507 - acc: 0.9570 - val_loss: 0.1587 - val_acc: 0.9568\n",
      "Epoch 32/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1473 - acc: 0.9579 - val_loss: 0.1558 - val_acc: 0.9578\n",
      "Epoch 33/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1441 - acc: 0.9592 - val_loss: 0.1540 - val_acc: 0.9578\n",
      "Epoch 34/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1411 - acc: 0.9599 - val_loss: 0.1511 - val_acc: 0.9585\n",
      "Epoch 35/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1381 - acc: 0.9607 - val_loss: 0.1498 - val_acc: 0.9593\n",
      "Epoch 36/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1355 - acc: 0.9615 - val_loss: 0.1475 - val_acc: 0.9602\n",
      "Epoch 37/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1326 - acc: 0.9622 - val_loss: 0.1452 - val_acc: 0.9609\n",
      "Epoch 38/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1296 - acc: 0.9632 - val_loss: 0.1448 - val_acc: 0.9603\n",
      "Epoch 39/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1275 - acc: 0.9641 - val_loss: 0.1421 - val_acc: 0.9618\n",
      "Epoch 40/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1247 - acc: 0.9650 - val_loss: 0.1397 - val_acc: 0.9612\n",
      "Epoch 41/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1224 - acc: 0.9656 - val_loss: 0.1378 - val_acc: 0.9627\n",
      "Epoch 42/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1201 - acc: 0.9664 - val_loss: 0.1362 - val_acc: 0.9622\n",
      "Epoch 43/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1178 - acc: 0.9665 - val_loss: 0.1349 - val_acc: 0.9634\n",
      "Epoch 44/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1156 - acc: 0.9679 - val_loss: 0.1331 - val_acc: 0.9633\n",
      "Epoch 45/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1133 - acc: 0.9683 - val_loss: 0.1330 - val_acc: 0.9634\n",
      "Epoch 46/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1115 - acc: 0.9688 - val_loss: 0.1302 - val_acc: 0.9642\n",
      "Epoch 47/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1093 - acc: 0.9694 - val_loss: 0.1288 - val_acc: 0.9644\n",
      "Epoch 48/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1074 - acc: 0.9700 - val_loss: 0.1283 - val_acc: 0.9642\n",
      "Epoch 49/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1055 - acc: 0.9704 - val_loss: 0.1266 - val_acc: 0.9653\n",
      "Epoch 50/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.1036 - acc: 0.9713 - val_loss: 0.1267 - val_acc: 0.9645\n",
      "Epoch 51/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1018 - acc: 0.9713 - val_loss: 0.1239 - val_acc: 0.9654\n",
      "Epoch 52/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1000 - acc: 0.9719 - val_loss: 0.1231 - val_acc: 0.9662\n",
      "Epoch 53/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0984 - acc: 0.9723 - val_loss: 0.1224 - val_acc: 0.9662\n",
      "Epoch 54/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0966 - acc: 0.9727 - val_loss: 0.1209 - val_acc: 0.9659\n",
      "Epoch 55/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0951 - acc: 0.9733 - val_loss: 0.1215 - val_acc: 0.9658\n",
      "Epoch 56/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0935 - acc: 0.9738 - val_loss: 0.1190 - val_acc: 0.9668\n",
      "Epoch 57/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0919 - acc: 0.9741 - val_loss: 0.1183 - val_acc: 0.9672\n",
      "Epoch 58/200\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0905 - acc: 0.9747 - val_loss: 0.1164 - val_acc: 0.9672\n",
      "Epoch 59/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0888 - acc: 0.9759 - val_loss: 0.1172 - val_acc: 0.9671\n",
      "Epoch 60/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0876 - acc: 0.9756 - val_loss: 0.1151 - val_acc: 0.9677\n",
      "Epoch 61/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0861 - acc: 0.9761 - val_loss: 0.1139 - val_acc: 0.9677\n",
      "Epoch 62/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0848 - acc: 0.9761 - val_loss: 0.1132 - val_acc: 0.9680\n",
      "Epoch 63/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0834 - acc: 0.9768 - val_loss: 0.1126 - val_acc: 0.9685\n",
      "Epoch 64/200\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.0823 - acc: 0.9769 - val_loss: 0.1117 - val_acc: 0.9685\n",
      "Epoch 65/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0809 - acc: 0.9775 - val_loss: 0.1105 - val_acc: 0.9685\n",
      "Epoch 66/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0797 - acc: 0.9780 - val_loss: 0.1104 - val_acc: 0.9697\n",
      "Epoch 67/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0784 - acc: 0.9780 - val_loss: 0.1095 - val_acc: 0.9698\n",
      "Epoch 68/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0773 - acc: 0.9788 - val_loss: 0.1088 - val_acc: 0.9694\n",
      "Epoch 69/200\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0761 - acc: 0.9789 - val_loss: 0.1105 - val_acc: 0.9687\n",
      "Epoch 70/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0750 - acc: 0.9793 - val_loss: 0.1083 - val_acc: 0.9697\n",
      "Epoch 71/200\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0740 - acc: 0.9797 - val_loss: 0.1067 - val_acc: 0.9698\n",
      "Epoch 72/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0727 - acc: 0.9802 - val_loss: 0.1062 - val_acc: 0.9702\n",
      "Epoch 73/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0718 - acc: 0.9801 - val_loss: 0.1057 - val_acc: 0.9707\n",
      "Epoch 74/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0706 - acc: 0.9810 - val_loss: 0.1051 - val_acc: 0.9701\n",
      "Epoch 75/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0698 - acc: 0.9810 - val_loss: 0.1044 - val_acc: 0.9702\n",
      "Epoch 76/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0687 - acc: 0.9814 - val_loss: 0.1039 - val_acc: 0.9708\n",
      "Epoch 77/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0677 - acc: 0.9816 - val_loss: 0.1031 - val_acc: 0.9708\n",
      "Epoch 78/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0668 - acc: 0.9821 - val_loss: 0.1029 - val_acc: 0.9706\n",
      "Epoch 79/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0658 - acc: 0.9827 - val_loss: 0.1027 - val_acc: 0.9713\n",
      "Epoch 80/200\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.0649 - acc: 0.9825 - val_loss: 0.1021 - val_acc: 0.9712\n",
      "Epoch 81/200\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0640 - acc: 0.9830 - val_loss: 0.1018 - val_acc: 0.9709\n",
      "Epoch 82/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0632 - acc: 0.9834 - val_loss: 0.1009 - val_acc: 0.9714\n",
      "Epoch 83/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0622 - acc: 0.9833 - val_loss: 0.1006 - val_acc: 0.9722\n",
      "Epoch 84/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0614 - acc: 0.9837 - val_loss: 0.1006 - val_acc: 0.9713\n",
      "Epoch 85/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0606 - acc: 0.9839 - val_loss: 0.0993 - val_acc: 0.9711\n",
      "Epoch 86/200\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.0598 - acc: 0.9841 - val_loss: 0.0995 - val_acc: 0.9716\n",
      "Epoch 87/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0589 - acc: 0.9840 - val_loss: 0.1006 - val_acc: 0.9727\n",
      "Epoch 88/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0581 - acc: 0.9845 - val_loss: 0.0991 - val_acc: 0.9719\n",
      "Epoch 89/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0574 - acc: 0.9849 - val_loss: 0.0987 - val_acc: 0.9723\n",
      "Epoch 90/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0567 - acc: 0.9850 - val_loss: 0.0983 - val_acc: 0.9724\n",
      "Epoch 91/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0559 - acc: 0.9851 - val_loss: 0.0985 - val_acc: 0.9723\n",
      "Epoch 92/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0551 - acc: 0.9854 - val_loss: 0.0988 - val_acc: 0.9724\n",
      "Epoch 93/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0544 - acc: 0.9855 - val_loss: 0.0967 - val_acc: 0.9726\n",
      "Epoch 94/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0538 - acc: 0.9860 - val_loss: 0.0973 - val_acc: 0.9733\n",
      "Epoch 95/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0530 - acc: 0.9860 - val_loss: 0.0962 - val_acc: 0.9732\n",
      "Epoch 96/200\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.0524 - acc: 0.9863 - val_loss: 0.0963 - val_acc: 0.9727\n",
      "Epoch 97/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0518 - acc: 0.9864 - val_loss: 0.0961 - val_acc: 0.9727\n",
      "Epoch 98/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0512 - acc: 0.9867 - val_loss: 0.0952 - val_acc: 0.9732\n",
      "Epoch 99/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0504 - acc: 0.9871 - val_loss: 0.0946 - val_acc: 0.9733\n",
      "Epoch 100/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0498 - acc: 0.9872 - val_loss: 0.0956 - val_acc: 0.9733\n",
      "Epoch 101/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0491 - acc: 0.9872 - val_loss: 0.0955 - val_acc: 0.9733\n",
      "Epoch 102/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0486 - acc: 0.9875 - val_loss: 0.0940 - val_acc: 0.9727\n",
      "Epoch 103/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0480 - acc: 0.9878 - val_loss: 0.0944 - val_acc: 0.9738\n",
      "Epoch 104/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0472 - acc: 0.9882 - val_loss: 0.0949 - val_acc: 0.9738\n",
      "Epoch 105/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0468 - acc: 0.9884 - val_loss: 0.0942 - val_acc: 0.9737\n",
      "Epoch 106/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0461 - acc: 0.9883 - val_loss: 0.0946 - val_acc: 0.9739\n",
      "Epoch 107/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0456 - acc: 0.9886 - val_loss: 0.0932 - val_acc: 0.9742\n",
      "Epoch 108/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0451 - acc: 0.9887 - val_loss: 0.0936 - val_acc: 0.9737\n",
      "Epoch 109/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0446 - acc: 0.9889 - val_loss: 0.0932 - val_acc: 0.9743\n",
      "Epoch 110/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0438 - acc: 0.9889 - val_loss: 0.0933 - val_acc: 0.9740\n",
      "Epoch 111/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0434 - acc: 0.9893 - val_loss: 0.0928 - val_acc: 0.9744\n",
      "Epoch 112/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0430 - acc: 0.9893 - val_loss: 0.0929 - val_acc: 0.9740\n",
      "Epoch 113/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0424 - acc: 0.9895 - val_loss: 0.0918 - val_acc: 0.9747\n",
      "Epoch 114/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0419 - acc: 0.9896 - val_loss: 0.0922 - val_acc: 0.9741\n",
      "Epoch 115/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0414 - acc: 0.9900 - val_loss: 0.0928 - val_acc: 0.9741\n",
      "Epoch 116/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0408 - acc: 0.9900 - val_loss: 0.0919 - val_acc: 0.9742\n",
      "Epoch 117/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0405 - acc: 0.9900 - val_loss: 0.0913 - val_acc: 0.9748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0399 - acc: 0.9903 - val_loss: 0.0921 - val_acc: 0.9740\n",
      "Epoch 119/200\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.0394 - acc: 0.9902 - val_loss: 0.0924 - val_acc: 0.9748\n",
      "Epoch 120/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0390 - acc: 0.9908 - val_loss: 0.0911 - val_acc: 0.9750\n",
      "Epoch 121/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0385 - acc: 0.9905 - val_loss: 0.0910 - val_acc: 0.9748\n",
      "Epoch 122/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0381 - acc: 0.9910 - val_loss: 0.0913 - val_acc: 0.9753\n",
      "Epoch 123/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0377 - acc: 0.9910 - val_loss: 0.0904 - val_acc: 0.9748\n",
      "Epoch 124/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0372 - acc: 0.9914 - val_loss: 0.0910 - val_acc: 0.9751\n",
      "Epoch 125/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0367 - acc: 0.9916 - val_loss: 0.0913 - val_acc: 0.9749\n",
      "Epoch 126/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0363 - acc: 0.9914 - val_loss: 0.0909 - val_acc: 0.9752\n",
      "Epoch 127/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0358 - acc: 0.9917 - val_loss: 0.0909 - val_acc: 0.9750\n",
      "Epoch 128/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0355 - acc: 0.9919 - val_loss: 0.0902 - val_acc: 0.9757\n",
      "Epoch 129/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0349 - acc: 0.9922 - val_loss: 0.0903 - val_acc: 0.9747\n",
      "Epoch 130/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0346 - acc: 0.9921 - val_loss: 0.0912 - val_acc: 0.9749\n",
      "Epoch 131/200\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0342 - acc: 0.9922 - val_loss: 0.0911 - val_acc: 0.9749\n",
      "Epoch 132/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0339 - acc: 0.9926 - val_loss: 0.0906 - val_acc: 0.9756\n",
      "Epoch 133/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0334 - acc: 0.9926 - val_loss: 0.0910 - val_acc: 0.9750\n",
      "Epoch 134/200\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.0330 - acc: 0.9927 - val_loss: 0.0900 - val_acc: 0.9759\n",
      "Epoch 135/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0327 - acc: 0.9929 - val_loss: 0.0898 - val_acc: 0.9750\n",
      "Epoch 136/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0323 - acc: 0.9929 - val_loss: 0.0908 - val_acc: 0.9763\n",
      "Epoch 137/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0320 - acc: 0.9930 - val_loss: 0.0895 - val_acc: 0.9751\n",
      "Epoch 138/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0316 - acc: 0.9932 - val_loss: 0.0900 - val_acc: 0.9756\n",
      "Epoch 139/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0312 - acc: 0.9931 - val_loss: 0.0902 - val_acc: 0.9758\n",
      "Epoch 140/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0309 - acc: 0.9935 - val_loss: 0.0901 - val_acc: 0.9744\n",
      "Epoch 141/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0304 - acc: 0.9932 - val_loss: 0.0903 - val_acc: 0.9753\n",
      "Epoch 142/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0302 - acc: 0.9936 - val_loss: 0.0897 - val_acc: 0.9753\n",
      "Epoch 143/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0298 - acc: 0.9937 - val_loss: 0.0893 - val_acc: 0.9753\n",
      "Epoch 144/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0294 - acc: 0.9937 - val_loss: 0.0902 - val_acc: 0.9751\n",
      "Epoch 145/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0291 - acc: 0.9938 - val_loss: 0.0893 - val_acc: 0.9757\n",
      "Epoch 146/200\n",
      "48000/48000 [==============================] - 1s 26us/step - loss: 0.0288 - acc: 0.9940 - val_loss: 0.0896 - val_acc: 0.9752\n",
      "Epoch 147/200\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0286 - acc: 0.9939 - val_loss: 0.0890 - val_acc: 0.9756\n",
      "Epoch 148/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0281 - acc: 0.9942 - val_loss: 0.0900 - val_acc: 0.9747\n",
      "Epoch 149/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0279 - acc: 0.9940 - val_loss: 0.0903 - val_acc: 0.9757\n",
      "Epoch 150/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0276 - acc: 0.9944 - val_loss: 0.0902 - val_acc: 0.9756\n",
      "Epoch 151/200\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.0272 - acc: 0.9940 - val_loss: 0.0899 - val_acc: 0.9756\n",
      "Epoch 152/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0269 - acc: 0.9945 - val_loss: 0.0897 - val_acc: 0.9754\n",
      "Epoch 153/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0266 - acc: 0.9948 - val_loss: 0.0895 - val_acc: 0.9752\n",
      "Epoch 154/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0263 - acc: 0.9946 - val_loss: 0.0900 - val_acc: 0.9755\n",
      "Epoch 155/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0260 - acc: 0.9947 - val_loss: 0.0895 - val_acc: 0.9752\n",
      "Epoch 156/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0257 - acc: 0.9948 - val_loss: 0.0896 - val_acc: 0.9748\n",
      "Epoch 157/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0255 - acc: 0.9948 - val_loss: 0.0895 - val_acc: 0.9751\n",
      "Epoch 158/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0252 - acc: 0.9950 - val_loss: 0.0898 - val_acc: 0.9754\n",
      "Epoch 159/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0249 - acc: 0.9951 - val_loss: 0.0907 - val_acc: 0.9740\n",
      "Epoch 160/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0246 - acc: 0.9952 - val_loss: 0.0896 - val_acc: 0.9748\n",
      "Epoch 161/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0244 - acc: 0.9952 - val_loss: 0.0901 - val_acc: 0.9753\n",
      "Epoch 162/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0241 - acc: 0.9954 - val_loss: 0.0912 - val_acc: 0.9751\n",
      "Epoch 163/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0238 - acc: 0.9954 - val_loss: 0.0898 - val_acc: 0.9750\n",
      "Epoch 164/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0236 - acc: 0.9956 - val_loss: 0.0893 - val_acc: 0.9750\n",
      "Epoch 165/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0233 - acc: 0.9956 - val_loss: 0.0896 - val_acc: 0.9752\n",
      "Epoch 166/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0230 - acc: 0.9955 - val_loss: 0.0900 - val_acc: 0.9751\n",
      "Epoch 167/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0227 - acc: 0.9956 - val_loss: 0.0893 - val_acc: 0.9749\n",
      "Epoch 168/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0225 - acc: 0.9956 - val_loss: 0.0902 - val_acc: 0.9752\n",
      "Epoch 169/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0223 - acc: 0.9958 - val_loss: 0.0896 - val_acc: 0.9750\n",
      "Epoch 170/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0221 - acc: 0.9957 - val_loss: 0.0896 - val_acc: 0.9752\n",
      "Epoch 171/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0218 - acc: 0.9958 - val_loss: 0.0905 - val_acc: 0.9748\n",
      "Epoch 172/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0216 - acc: 0.9960 - val_loss: 0.0910 - val_acc: 0.9751\n",
      "Epoch 173/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0213 - acc: 0.9959 - val_loss: 0.0906 - val_acc: 0.9749\n",
      "Epoch 174/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0211 - acc: 0.9957 - val_loss: 0.0902 - val_acc: 0.9750\n",
      "Epoch 175/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0208 - acc: 0.9961 - val_loss: 0.0899 - val_acc: 0.9753\n",
      "Epoch 176/200\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0206 - acc: 0.9961 - val_loss: 0.0905 - val_acc: 0.9753\n",
      "Epoch 177/200\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.0204 - acc: 0.9963 - val_loss: 0.0903 - val_acc: 0.9748\n",
      "Epoch 178/200\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0202 - acc: 0.9964 - val_loss: 0.0910 - val_acc: 0.9745\n",
      "Epoch 179/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0200 - acc: 0.9962 - val_loss: 0.0903 - val_acc: 0.9751\n",
      "Epoch 180/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0198 - acc: 0.9963 - val_loss: 0.0907 - val_acc: 0.9753\n",
      "Epoch 181/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0196 - acc: 0.9964 - val_loss: 0.0915 - val_acc: 0.9753\n",
      "Epoch 182/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0193 - acc: 0.9966 - val_loss: 0.0910 - val_acc: 0.9755\n",
      "Epoch 183/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0192 - acc: 0.9965 - val_loss: 0.0906 - val_acc: 0.9750\n",
      "Epoch 184/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0190 - acc: 0.9966 - val_loss: 0.0908 - val_acc: 0.9751\n",
      "Epoch 185/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0187 - acc: 0.9967 - val_loss: 0.0905 - val_acc: 0.9752\n",
      "Epoch 186/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0186 - acc: 0.9967 - val_loss: 0.0907 - val_acc: 0.9753\n",
      "Epoch 187/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0184 - acc: 0.9968 - val_loss: 0.0908 - val_acc: 0.9747\n",
      "Epoch 188/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0182 - acc: 0.9969 - val_loss: 0.0905 - val_acc: 0.9751\n",
      "Epoch 189/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0180 - acc: 0.9969 - val_loss: 0.0908 - val_acc: 0.9750\n",
      "Epoch 190/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0178 - acc: 0.9970 - val_loss: 0.0910 - val_acc: 0.9750\n",
      "Epoch 191/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0177 - acc: 0.9971 - val_loss: 0.0908 - val_acc: 0.9753\n",
      "Epoch 192/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0174 - acc: 0.9971 - val_loss: 0.0906 - val_acc: 0.9753\n",
      "Epoch 193/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0173 - acc: 0.9971 - val_loss: 0.0911 - val_acc: 0.9750\n",
      "Epoch 194/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0170 - acc: 0.9973 - val_loss: 0.0911 - val_acc: 0.9748\n",
      "Epoch 195/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0169 - acc: 0.9972 - val_loss: 0.0912 - val_acc: 0.9749\n",
      "Epoch 196/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0167 - acc: 0.9974 - val_loss: 0.0909 - val_acc: 0.9752\n",
      "Epoch 197/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0165 - acc: 0.9974 - val_loss: 0.0916 - val_acc: 0.9748\n",
      "Epoch 198/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0163 - acc: 0.9975 - val_loss: 0.0918 - val_acc: 0.9753\n",
      "Epoch 199/200\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0162 - acc: 0.9975 - val_loss: 0.0914 - val_acc: 0.9750\n",
      "Epoch 200/200\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0161 - acc: 0.9976 - val_loss: 0.0911 - val_acc: 0.9753\n",
      "10000/10000 [==============================] - 0s 25us/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test score: 0.2771490333199501\n",
      "Test accuracy: 0.9234\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJmjmslsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
